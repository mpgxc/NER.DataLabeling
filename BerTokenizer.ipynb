{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BerTokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WbDje0GMPMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cdcc28-eec2-4a65-e2b7-bc5bbd0ddfa4"
      },
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install transformers\n",
        "# !pip install seqeval"
      ],
      "id": "2WbDje0GMPMG",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (19.3.1)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITxwi4CeM3mA"
      },
      "source": [
        "import os"
      ],
      "id": "ITxwi4CeM3mA",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTnE6MWpM0p5",
        "outputId": "22095c00-86e3-40ba-e006-303c3a13a4fd"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"xwalker\" # Usuário Kaggle\n",
        "os.environ['KAGGLE_KEY'] = \"799d9818e9349a3dd767276d469df34a\" # Token de Acesso\n",
        "\n",
        "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus\n",
        "\n",
        "!unzip entity-annotated-corpus.zip"
      ],
      "id": "nTnE6MWpM0p5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  entity-annotated-corpus.zip\n",
            "replace ner.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ner.csv                 \n",
            "replace ner_dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "handy-convert"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import metrics, optimizers, losses\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from seqeval.metrics import f1_score, classification_report, accuracy_score"
      ],
      "id": "handy-convert",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spatial-gross"
      },
      "source": [
        "BERT_MODEL_NAME = 'bert-base-uncased'"
      ],
      "id": "spatial-gross",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlike-nightlife"
      },
      "source": [
        "data = pd.read_csv('ner_dataset.csv', sep=\",\", encoding=\"latin1\").fillna(method='ffill')"
      ],
      "id": "unlike-nightlife",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "express-interval"
      },
      "source": [
        "class ContextNER:\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.__df = df\n",
        "\n",
        "        self.all_words = set(df.Word.values)\n",
        "        self.all_tags = set(df.Tag.values)\n",
        "\n",
        "        self.num_words = len(self.all_words)\n",
        "        self.num_tags = len(self.all_tags) + 1\n",
        "\n",
        "        self.sentences = self.__build_sentences()\n",
        "        self.max_len = self.__get_maxlen()\n",
        "\n",
        "        self.__build_Xy()\n",
        "        self.__build_parsers()\n",
        "\n",
        "    def __get_maxlen(self):\n",
        "        return max([len(x) for x in self.sentences]) \n",
        "\n",
        "    def __build_sentences(self):\n",
        "\n",
        "        return [x for x in self.__df.groupby('Sentence #').apply(\n",
        "            lambda xdef: [x for x in zip(\n",
        "                xdef.Word.values,\n",
        "                xdef.Tag.values\n",
        "            )]\n",
        "        )]\n",
        "\n",
        "    def __build_Xy(self):\n",
        "\n",
        "        self.X = [[word for word, __ in value] for value in self.sentences]\n",
        "        self.y = [[tag for __, tag in value] for value in self.sentences]\n",
        "\n",
        "    def __build_parsers(self):\n",
        "\n",
        "        self.word2idx = {value: idx for idx,\n",
        "                         value in enumerate(self.all_words)}\n",
        "\n",
        "        # Converte um index em Word\n",
        "        self.idx2word = {idx: value for value, idx in self.word2idx.items()}\n",
        "\n",
        "        # Converte Tag em ìndice\n",
        "        self.tag2idx = {value: idx + 1 for idx,\n",
        "                        value in enumerate(self.all_tags)}\n",
        "        self.tag2idx[\"[PAD]\"] = 0  # Padding - Preenchimento\n",
        "\n",
        "        # Converte index em Tag\n",
        "        self.idx2tag = {idx: value for value, idx in self.tag2idx.items()}"
      ],
      "id": "express-interval",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amateur-recommendation"
      },
      "source": [
        "contextNER = ContextNER(data)"
      ],
      "id": "amateur-recommendation",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canadian-senior"
      },
      "source": [
        "Words, Tags = contextNER.X, contextNER.y"
      ],
      "id": "canadian-senior",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo9Vxk7MeDai"
      },
      "source": [
        "def __bert_encode(texts, tokenizer, max_len=None):\n",
        "    \n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len - 2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "id": "zo9Vxk7MeDai",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "concerned-lounge"
      },
      "source": [
        "max_seq_length = contextNER.max_len\n",
        "\n",
        "pad_token_label_id = 0\n",
        "special_tokens_count =  2\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, \n",
        "                                        do_lower_case=False)\n",
        "\n",
        "def convert_to_input(sentences, tags):\n",
        "\n",
        "    input_id_list, attention_mask_list, token_type_id_list = [], [], []\n",
        "    label_id_list = []\n",
        "  \n",
        "    for x, y in tqdm(zip(sentences, tags), total = len(tags)):\n",
        "  \n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "\n",
        "        for word, label in zip(x, y):\n",
        "            \n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_tokens)\n",
        "            label_ids.extend([contextNER.tag2idx[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
        "            \n",
        "        if len(tokens) > max_seq_length - special_tokens_count:\n",
        "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
        "            label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "        label_ids = [pad_token_label_id] + label_ids + [pad_token_label_id]\n",
        "        inputs = tokenizer.encode_plus(tokens,\n",
        "                                       add_special_tokens=True, \n",
        "                                       truncation=True,\n",
        "                                       max_length=max_seq_length)\n",
        "\n",
        "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "        attention_masks = [1] * len(input_ids)\n",
        "\n",
        "        attention_mask_list.append(attention_masks)\n",
        "        input_id_list.append(input_ids)\n",
        "        token_type_id_list.append(token_type_ids)\n",
        "\n",
        "        label_id_list.append(label_ids)\n",
        "\n",
        "    return input_id_list, token_type_id_list, attention_mask_list, label_id_list\n",
        "\n",
        "\n",
        "def pad_seq(seq, max_seq_length):\n",
        "    return pad_sequences(seq,\n",
        "                         maxlen=max_seq_length,\n",
        "                         dtype=\"long\",\n",
        "                         truncating=\"post\",\n",
        "                         padding=\"post\")"
      ],
      "id": "concerned-lounge",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "divided-racing",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5835e5-0755-49fc-bafa-646fada7acc7"
      },
      "source": [
        "input_ids_train, token_ids_train, attention_masks_train, label_ids_train = convert_to_input(Words, Tags)"
      ],
      "id": "divided-racing",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47959/47959 [01:09<00:00, 685.49it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "responsible-devil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f5b2e3-bee0-4297-c5e8-e2bda3c15f28"
      },
      "source": [
        "for token_id, tag_id in zip(input_ids_train[0], label_ids_train[0]):\n",
        "    \n",
        "    word = tokenizer.convert_ids_to_tokens(token_id)\n",
        "    tag = contextNER.idx2tag[tag_id]\n",
        "    \n",
        "    print(token_id, ' - ', word, ' - ', tag)"
      ],
      "id": "responsible-devil",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101  -  [CLS]  -  [PAD]\n",
            "100  -  [UNK]  -  O\n",
            "1997  -  of  -  O\n",
            "28337  -  demonstrators  -  O\n",
            "2031  -  have  -  O\n",
            "9847  -  marched  -  O\n",
            "2083  -  through  -  O\n",
            "100  -  [UNK]  -  B-geo\n",
            "2000  -  to  -  O\n",
            "6186  -  protest  -  O\n",
            "1996  -  the  -  O\n",
            "2162  -  war  -  O\n",
            "1999  -  in  -  O\n",
            "100  -  [UNK]  -  B-geo\n",
            "1998  -  and  -  O\n",
            "5157  -  demand  -  O\n",
            "1996  -  the  -  O\n",
            "10534  -  withdrawal  -  O\n",
            "1997  -  of  -  O\n",
            "100  -  [UNK]  -  B-gpe\n",
            "3629  -  troops  -  O\n",
            "2013  -  from  -  O\n",
            "2008  -  that  -  O\n",
            "2406  -  country  -  O\n",
            "1012  -  .  -  O\n",
            "102  -  [SEP]  -  [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "visible-maple"
      },
      "source": [
        "input_ids_train = pad_seq(input_ids_train, max_seq_length)\n",
        "token_ids_train = pad_seq(token_ids_train, max_seq_length)\n",
        "attention_masks_train = pad_seq(attention_masks_train, max_seq_length)\n",
        "label_ids_train = pad_seq(label_ids_train, max_seq_length)"
      ],
      "id": "visible-maple",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "persistent-harmony"
      },
      "source": [
        "# Model"
      ],
      "id": "persistent-harmony"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "furnished-depth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09be8f9-d945-410b-bcd3-66880da391f2"
      },
      "source": [
        "input_ids = layers.Input(shape=(max_seq_length,), \n",
        "                         dtype=tf.int32, \n",
        "                         name=\"input_ids\")\n",
        "\n",
        "token_type_ids = layers.Input(shape=(max_seq_length,), \n",
        "                              dtype=tf.int32, \n",
        "                              name=\"attention_masks\")\n",
        "\n",
        "attention_masks = layers.Input(shape=(max_seq_length,), \n",
        "                               dtype=tf.int32,\n",
        "                               name=\"token_type_ids\")\n",
        "\n",
        "bert_inputs = [input_ids, token_type_ids, attention_masks]\n",
        "\n",
        "bert_configs = BertConfig.from_pretrained(BERT_MODEL_NAME, num_labels=contextNER.num_tags)\n",
        "bert_model = TFBertModel.from_pretrained(BERT_MODEL_NAME, config=bert_configs)\n",
        "bert_model.trainable = False\n",
        "\n",
        "sequence_output = bert_model(bert_inputs)[0]\n",
        "\n",
        "# Recebe os embedings/features da camada pre-treinada anterior (BERT)\n",
        "\n",
        "# bi_lstm = layers.Bidirectional(layers.LSTM(max_seq_length // 2, \n",
        "#                                            return_sequences=True,\n",
        "#                                            recurrent_dropout=0.1), name='bilstm')(sequence_output)\n",
        "\n",
        "# Usar com GPU para acelerar treinamento\n",
        "bi_lstm = layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(max_seq_length // 2, \n",
        "                                                             return_sequences=True),\n",
        "                                                             name='bilstm')(sequence_output)\n",
        "\n",
        "dropout = layers.TimeDistributed(layers.Dropout(0.3))(bi_lstm)\n",
        "\n",
        "dense_layer = layers.TimeDistributed(layers.Dense(max_seq_length,\n",
        "                                                  activation='relu',\n",
        "                                                  name='last_dense'))(dropout)\n",
        "\n",
        "output = layers.Dense(contextNER.num_tags,\n",
        "                               activation=\"softmax\",\n",
        "                               name='predictions')(dense_layer)\n",
        "\n",
        "model = models.Model(inputs=bert_inputs, outputs=output)\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
        "              loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[metrics.SparseCategoricalAccuracy('accuracy')])"
      ],
      "id": "furnished-depth",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ethical-greene",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2005007-fc5e-4029-e062-61b61ac0eaea"
      },
      "source": [
        "model.summary()"
      ],
      "id": "ethical-greene",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 104)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 104)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 104)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_3 (TFBertModel)   TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 token_type_ids[0][0]             \n",
            "                                                                 attention_masks[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bilstm (Bidirectional)          (None, 104, 104)     341952      tf_bert_model_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 104, 104)     0           bilstm[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 104, 18)      1890        time_distributed_6[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 109,826,082\n",
            "Trainable params: 343,842\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "critical-frederick"
      },
      "source": [
        "x_train = [input_ids_train,\n",
        "           attention_masks_train,\n",
        "           token_ids_train]"
      ],
      "id": "critical-frederick",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd11u55YN7V5",
        "outputId": "b70eead2-45d7-49f1-cc82-23b8b7c11104"
      },
      "source": [
        "history = model.fit(x=x_train,\n",
        "                    y=label_ids_train,\n",
        "                    validation_split=0.3, \n",
        "                    batch_size=16, \n",
        "                    epochs=3) "
      ],
      "id": "kd11u55YN7V5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "2099/2099 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.9348WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MYsOmdDwmcO"
      },
      "source": [
        ""
      ],
      "id": "8MYsOmdDwmcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7pZOsgAPuZH"
      },
      "source": [
        "history.history"
      ],
      "id": "t7pZOsgAPuZH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBfJ8afhZ7rX"
      },
      "source": [
        "model."
      ],
      "id": "VBfJ8afhZ7rX",
      "execution_count": null,
      "outputs": []
    }
  ]
}