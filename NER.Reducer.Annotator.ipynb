{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f7d56e-2d97-4020-9fb2-c6a3fd0734db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./requeriments.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import spacy\n",
    "import stanza\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mode, StatisticsError\n",
    "from spacy import displacy\n",
    "from matplotlib import pyplot as plt\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handled-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/custom/DATA_PROCESSADO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-independence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long over due !! and lizzo was fire AF omg !!!</td>\n",
       "      <td>long over due !! and lizzo was fire af omg !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Another Bachour Class at bachour1234 with pavo...</td>\n",
       "      <td>another bachour class at bachour1234 with pavo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Always happy to be here need to move here forever</td>\n",
       "      <td>always happy to be here need to move here forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morning love it up North this morning First Wa...</td>\n",
       "      <td>morning love it up north this morning first wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are your flaws that only God can anoint a...</td>\n",
       "      <td>what are your flaws that only god can anoint a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0     Long over due !! and lizzo was fire AF omg !!!   \n",
       "1  Another Bachour Class at bachour1234 with pavo...   \n",
       "2  Always happy to be here need to move here forever   \n",
       "3  Morning love it up North this morning First Wa...   \n",
       "4  What are your flaws that only God can anoint a...   \n",
       "\n",
       "                                          text_lower  \n",
       "0     long over due !! and lizzo was fire af omg !!!  \n",
       "1  another bachour class at bachour1234 with pavo...  \n",
       "2  always happy to be here need to move here forever  \n",
       "3  morning love it up north this morning first wa...  \n",
       "4  what are your flaws that only god can anoint a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cd0dde-e521-46b1-8c38-68776c0f9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu() \n",
    "stanza.download('en', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dress-denver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/mpgxc/anaconda3/lib/python3.8/site-packages/en_core_web_trf/en_core_web_trf-3.1.0/transformer/model were not used when initializing RobertaModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nlp_spacy_model = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "nlp_spacy_model_lg = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "nlp_stanza_model = stanza.Pipeline(lang='en', \n",
    "                                   use_gpu=False,\n",
    "                                   verbose=False,\n",
    "                                   processors={'tokenize': 'spacy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monthly-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean_text(text):\n",
    "    return \" \".join(text.replace('\\n', '').split())\n",
    "\n",
    "def chunk_class(tag):\n",
    "    \n",
    "    \"\"\"\n",
    "        Converte as classes Spacy em um modelo customizado...\n",
    "    \"\"\"\n",
    "    \n",
    "    final = tag\n",
    "    \n",
    "    try:\n",
    "        pre, suf = tag.split('-')\n",
    "    except:\n",
    "        return final\n",
    "    \n",
    "    if suf == 'PERSON': \n",
    "        final = pre + '-PER'\n",
    "        \n",
    "        \n",
    "    if suf == 'GPE' or suf == 'FAC': \n",
    "        final = pre + '-LOC'\n",
    "        \n",
    "    return final\n",
    "\n",
    "def stanza_parser_tags(tag):\n",
    "    \n",
    "    if tag != 'O':\n",
    "        prefix, sufix = tag.split('-')\n",
    "        if  prefix == \"E\": return 'I-' + sufix\n",
    "        elif prefix == 'S': return 'B-' +  sufix\n",
    "        else: return tag\n",
    "    else: return tag\n",
    "    \n",
    "def spacy_annotator(index, sentence, apply_func):\n",
    "    \n",
    "    document = apply_func(sentence)\n",
    "\n",
    "    orgin_tokens = []\n",
    "    origin_tags = []\n",
    "    \n",
    "    for word_obj in document:\n",
    "        \n",
    "        tmp_tag = 'O'\n",
    "        if word_obj.ent_iob_ != 'O':\n",
    "            tmp_tag = word_obj.ent_iob_+ '-' + word_obj.ent_type_\n",
    "\n",
    "        orgin_tokens.append(str(word_obj))\n",
    "        origin_tags.append(chunk_class(tmp_tag))\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        \"Sentence\": ['Sentence #' + str(index)] * len(orgin_tokens),\n",
    "        \"Word\": orgin_tokens,\n",
    "        \"Tag\": origin_tags\n",
    "    })\n",
    "    \n",
    "def stanza_annotator(index, text, apply_func):\n",
    "    \n",
    "    doc = apply_func(text)\n",
    "    \n",
    "    words = []\n",
    "    tags = []\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        for token in sent.tokens:\n",
    "    \n",
    "            words.append(token.text)\n",
    "            #CONVERTE BILOUS TO BIO\n",
    "            bio_tag = stanza_parser_tags(token.ner)\n",
    "            \n",
    "            tags.append(chunk_class(bio_tag))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"Sentence\": ['Sentence #' + str(index)] * len(words),\n",
    "        \"Word\": words,\n",
    "        \"Tag\": tags\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-retrieval",
   "metadata": {},
   "source": [
    "## Reducer NER Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "requested-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_ner_class(candidates_preds):\n",
    "\n",
    "    if not isinstance(candidates_preds, zip):\n",
    "        raise Exception(\"Tipo de estrutura não é aceita!\")\n",
    "     \n",
    "    def __majority(candidate_tags): \n",
    "        try:\n",
    "            return mode(candidate_tags)\n",
    "        except StatisticsError:\n",
    "            return 'O'\n",
    "\n",
    "    return [__majority(tags) for tags in candidates_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "moderate-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a083fa346440659b6b23d51398d58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 4min 3s, sys: 554 ms, total: 4min 4s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "final_data_annotate = pd.DataFrame()\n",
    "\n",
    "for index, text in enumerate(tqdm.notebook.tqdm(data.text[:100])):\n",
    "    \n",
    "    preproc_text = simple_clean_text(text)\n",
    "    \n",
    "    # Predictions #1\n",
    "    stanza_pd = stanza_annotator(index,\n",
    "                                 preproc_text,\n",
    "                                 nlp_stanza_model)\n",
    "    # Predictions #2\n",
    "    spacy_pd = spacy_annotator(index,\n",
    "                               preproc_text,\n",
    "                               nlp_spacy_model)\n",
    "    # Predictions #3\n",
    "    spacy_pd_lg = spacy_annotator(index,\n",
    "                                  preproc_text,\n",
    "                                  nlp_spacy_model_lg)\n",
    "    \n",
    "    # Majority Vote or Mode\n",
    "    stanza_pd.Tag = reduce_ner_class(zip(stanza_pd.Tag,\n",
    "                                         spacy_pd.Tag,\n",
    "                                         spacy_pd_lg.Tag))\n",
    "    \n",
    "    if len(stanza_pd.Tag.value_counts()) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        # Append on Final Model\n",
    "        final_data_annotate = final_data_annotate.append(stanza_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5349f682-f060-416a-87fb-56eaf850c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence #3</td>\n",
       "      <td>Morning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence #3</td>\n",
       "      <td>love</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence #3</td>\n",
       "      <td>it</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence #3</td>\n",
       "      <td>up</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence #3</td>\n",
       "      <td>North</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence #99</td>\n",
       "      <td>down</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence #99</td>\n",
       "      <td>Jess</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence #99</td>\n",
       "      <td>Frank</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence #99</td>\n",
       "      <td>Golf</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence #99</td>\n",
       "      <td>Academy</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence     Word    Tag\n",
       "0    Sentence #3  Morning      O\n",
       "1    Sentence #3     love      O\n",
       "2    Sentence #3       it      O\n",
       "3    Sentence #3       up      O\n",
       "4    Sentence #3    North  B-PER\n",
       "..           ...      ...    ...\n",
       "15  Sentence #99     down      O\n",
       "16  Sentence #99     Jess  B-ORG\n",
       "17  Sentence #99    Frank  I-ORG\n",
       "18  Sentence #99     Golf  I-ORG\n",
       "19  Sentence #99  Academy  I-ORG\n",
       "\n",
       "[1503 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83f770dc-9e04-47e3-880f-d3718266433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_annotate.to_excel('data/final_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb4e7e-5401-405c-b581-c50ccba6e495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
