{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thrown-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seqeval.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import layers, metrics, optimizers, losses, Model\n",
    "\n",
    "from crf_layer import CRF\n",
    "from preprocessing.contextNER import ContextNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sunrise-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/kaggle_ner.csv', sep=\",\", encoding=\"latin1\").fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "digital-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ner = ContextNER(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graduate-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST  = train_test_split(data_ner.X_array,\n",
    "                                                     data_ner.y_array, \n",
    "                                                     test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-cliff",
   "metadata": {},
   "source": [
    "# *Custom Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "applied-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_MODEL(Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 configs_ner_params=None, \n",
    "                 dropout_rate=0.1,\n",
    "                 use_crf=False,\n",
    "                 hiden_units=128):\n",
    "        \n",
    "        super(NER_MODEL, self).__init__()\n",
    "\n",
    "        self.configs_ner_params = configs_ner_params\n",
    "        self.hiden_units = hiden_units\n",
    "        self.use_crf = use_crf\n",
    "        \n",
    "        self.embedding = layers.Embedding(input_dim=configs_ner_params.num_words,\n",
    "                                          output_dim=configs_ner_params.max_len,\n",
    "                                          input_length=configs_ner_params.max_len)\n",
    "        \n",
    "        self.dropout = layers.TimeDistributed(layers.Dropout(dropout_rate))\n",
    "            \n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(units=hiden_units // 2,\n",
    "                                                       return_sequences=True,\n",
    "                                                       recurrent_dropout=0.1))\n",
    "        \n",
    "        self.dense_crf = layers.TimeDistributed(layers.Dense(units=configs_ner_params.num_tags, \n",
    "                                                             activation='relu'))\n",
    "\n",
    "        self.classifier_crf = CRF(configs_ner_params.num_tags, \n",
    "                                  sparse_target=True)\n",
    "\n",
    "        self.dense = layers.TimeDistributed(layers.Dense(units=self.hiden_units, \n",
    "                                                         activation='relu'))\n",
    "\n",
    "        self.classifier_softmax = layers.TimeDistributed(layers.Dense(units=configs_ner_params.num_tags, \n",
    "                                                                      activation='softmax'))\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        X = self.embedding(inputs)\n",
    "        X = self.dropout(X)\n",
    "        X = self.bilstm(X)\n",
    "        \n",
    "        if self.use_crf:\n",
    "            \n",
    "            X = self.dense_crf(X)\n",
    "            X = self.classifier_crf(X)\n",
    "        else:\n",
    "            \n",
    "            X = self.dense(X)\n",
    "            X = self.classifier_softmax(X)\n",
    "            \n",
    "        return X\n",
    "        \n",
    "    def model(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            Implementação baseada na API Funcional, permite utilizar o método 'model.summary' \n",
    "            antes de executar o método 'model.fit'\n",
    "            \n",
    "            Retorna o modelo compilado com base no classificador CRF / SOFTMAX\n",
    "            \n",
    "            parâmetro: use_crf\n",
    "        \"\"\"\n",
    "        \n",
    "        X = layers.Input(shape=(self.configs_ner_params.max_len,))\n",
    "        \n",
    "        X = Model(inputs=[X], outputs=self.call(X))\n",
    "        \n",
    "        optm = optimizers.Adam(lr=0.001)\n",
    "\n",
    "        if self.use_crf:\n",
    "            X.compile(optimizer=optm,\n",
    "                      loss=self.classifier_crf.loss,\n",
    "                      metrics=[self.classifier_crf.accuracy])\n",
    "        else:\n",
    "            X.compile(optimizer=optm,\n",
    "                      loss=losses.CategoricalCrossentropy(),\n",
    "                      metrics=metrics.CategoricalAccuracy('accuracy'))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tribal-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NER_MODEL(data_ner, use_crf=True).model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "korean-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 105)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 105, 105)          3693900   \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 105, 105)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 105, 128)          87040     \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 105, 18)           2322      \n",
      "_________________________________________________________________\n",
      "crf_9 (CRF)                  (None, 105, 18)           324       \n",
      "=================================================================\n",
      "Total params: 3,783,586\n",
      "Trainable params: 3,783,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging = TensorBoard(log_dir='./logs',\n",
    "                      write_graph=True, \n",
    "                      write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_TRAIN, \n",
    "          Y_TRAIN, \n",
    "          validation_split=0.2, \n",
    "          batch_size=64, \n",
    "          epochs=5,\n",
    "          callbacks=[logging])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_TEST, verbose=1, batch_size=64)\n",
    "                      \n",
    "y_pred, y_true = \\\n",
    "np.argmax(preds, axis=-1), \\\n",
    "np.argmax(Y_TEST, -1)\n",
    "\n",
    "pred_tag, true_tag = \\\n",
    "data_ner.parser2categorical(y_pred, y_true) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(pred_tag, true_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(pred_tag, true_tag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
