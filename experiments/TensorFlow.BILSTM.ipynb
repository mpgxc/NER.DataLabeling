{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thrown-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seqeval.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from tensorflow.keras import layers, metrics, optimizers, losses, Model\n",
    "\n",
    "from crf_layer import CRF\n",
    "from preprocessing.contextNER import ContextNER\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sunrise-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/custom/DATA_TWEETS_VACINAS_PT_BR.csv')# sep=\",\", encoding=\"latin1\").fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1137e80-09aa-413e-abc4-e24575df4eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence #0</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence #0</td>\n",
       "      <td>terceira</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence #0</td>\n",
       "      <td>dose</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence #0</td>\n",
       "      <td>da</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence #0</td>\n",
       "      <td>vacina</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886079</th>\n",
       "      <td>Sentence #69467</td>\n",
       "      <td>vacina</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886080</th>\n",
       "      <td>Sentence #69467</td>\n",
       "      <td>.O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886081</th>\n",
       "      <td>Sentence #69467</td>\n",
       "      <td>Governo</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886082</th>\n",
       "      <td>Sentence #69467</td>\n",
       "      <td>…</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886083</th>\n",
       "      <td>Sentence #69467</td>\n",
       "      <td>https://t.co/hRNYsrldJz</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>886084 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                     Word Tag\n",
       "0           Sentence #0                        A   O\n",
       "1           Sentence #0                 terceira   O\n",
       "2           Sentence #0                     dose   O\n",
       "3           Sentence #0                       da   O\n",
       "4           Sentence #0                   vacina   O\n",
       "...                 ...                      ...  ..\n",
       "886079  Sentence #69467                   vacina   O\n",
       "886080  Sentence #69467                       .O   O\n",
       "886081  Sentence #69467                  Governo   O\n",
       "886082  Sentence #69467                        …   O\n",
       "886083  Sentence #69467  https://t.co/hRNYsrldJz   O\n",
       "\n",
       "[886084 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ner = ContextNER(data, groupby='Sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d095ce54-4195-4c64-aadc-874c63fe068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextNER:\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.__df = df\n",
    "\n",
    "        self.all_words = set(df.Word.values)\n",
    "        self.all_tags = set(df.Tag.values)\n",
    "\n",
    "        self.num_words = len(self.all_words)\n",
    "        self.num_tags = len(self.all_tags)\n",
    "\n",
    "        self.sentences = self.__build_sentences()\n",
    "        self.max_len = self.__get_maxlen()\n",
    "\n",
    "        self.__build_Xy()\n",
    "        self.__build_parsers()\n",
    "\n",
    "    def __get_maxlen(self):\n",
    "        return max([len(x) for x in self.sentences]) \n",
    "\n",
    "    def __build_sentences(self):\n",
    "\n",
    "        return [x for x in self.__df.groupby('Sentence #').apply(\n",
    "            lambda xdef: [x for x in zip(\n",
    "                xdef.Word.values,\n",
    "                xdef.Tag.values\n",
    "            )]\n",
    "        )]\n",
    "\n",
    "    def __build_Xy(self):\n",
    "\n",
    "        self.X = [[word for word, __ in value] for value in self.sentences]\n",
    "        self.y = [[tag for __, tag in value] for value in self.sentences]\n",
    "\n",
    "    def __build_parsers(self):\n",
    "        \n",
    "        self.tag2idx = {value: idx for idx, value in enumerate(self.all_tags)}\n",
    "        self.idx2tag = {idx: value for value, idx in self.tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graduate-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST  = train_test_split(data_ner.X_array,\n",
    "                                                     data_ner.y_array,\n",
    "                                                     random_state=42,\n",
    "                                                     test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10614a06-50ff-4f18-9259-6111902ab2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31325, 66), (13425, 66))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN.shape, X_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed4029a-ec24-417d-880b-93dfa8e3ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics(pred_tag, true_tag):\n",
    "\n",
    "    print(classification_report(pred_tag, true_tag))\n",
    "    print('=' * 25)\n",
    "    print(\"Precision: \\t\", precision_score(pred_tag, true_tag))\n",
    "    print(\"Recall: \\t\", recall_score(pred_tag, true_tag))\n",
    "    print(\"F1: \\t\\t\", f1_score(pred_tag, true_tag))\n",
    "    \n",
    "def build_matrix_embeddings(path, num_tokens, embedding_dim, word_index):\n",
    "    \"\"\"\n",
    "        Função para carregar arquivos pre-treinados em memória\n",
    "    \"\"\"\n",
    "\n",
    "    hits, misses = 0, 0\n",
    "    embeddings_index = {}\n",
    "\n",
    "    print('Loading file...')\n",
    "\n",
    "    sleep(0.5)\n",
    "\n",
    "    for line in tqdm(open(path, encoding='utf-8')):\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        embeddings_index[word] = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "\n",
    "    print(\"Encontrado %s Word Vectors.\" % len(embeddings_index))\n",
    "\n",
    "    sleep(0.5)\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= num_tokens:\n",
    "            continue\n",
    "        try:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                hits += 1\n",
    "            else:\n",
    "                embedding_vector = embeddings_index.get(str(word).lower())\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    hits += 1\n",
    "                else:\n",
    "                    embedding_vector = embeddings_index.get(str(word).upper())\n",
    "                    if embedding_vector is not None:\n",
    "                        embedding_matrix[i] = embedding_vector\n",
    "                        hits += 1\n",
    "                misses += 1\n",
    "        except:\n",
    "            embedding_matrix[i] = embeddings_index.get('UNK')\n",
    "\n",
    "    print(\"Convertidos: %d Tokens | Perdidos: %d Tokens\" % (hits, misses))\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-cliff",
   "metadata": {},
   "source": [
    "# *Custom Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "applied-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_MODEL(Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 configs_ner_params=None, \n",
    "                 dropout_rate=0.3,\n",
    "                 embeddings=None,\n",
    "                 use_crf=False,\n",
    "                 hiden_units=256):\n",
    "        \n",
    "        super(NER_MODEL, self).__init__()\n",
    "\n",
    "        self.configs_ner_params = configs_ner_params\n",
    "        self.hiden_units = hiden_units\n",
    "        self.use_crf = use_crf\n",
    "\n",
    "        self.embedding = layers.Embedding(input_length=configs_ner_params.max_len, \n",
    "                                          input_dim=embeddings.shape[0],\n",
    "                                          output_dim=embeddings.shape[1],\n",
    "                                          weights=[embeddings],\n",
    "                                          trainable=True)\n",
    "     \n",
    "         #         self.embedding = layers.Embedding(input_dim=configs_ner_params.num_words,\n",
    "         #                                           output_dim=configs_ner_params.max_len,\n",
    "         #                                           input_length=configs_ner_params.max_len)\n",
    "\n",
    "        self.dropout = layers.TimeDistributed(layers.Dropout(dropout_rate))\n",
    "            \n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(units=hiden_units // 2,\n",
    "                                                       return_sequences=True,\n",
    "                                                       recurrent_dropout=0.1))\n",
    "        \n",
    "        self.dense_crf = layers.TimeDistributed(layers.Dense(units=configs_ner_params.num_tags, \n",
    "                                                             activation='relu'))\n",
    "\n",
    "        self.classifier_crf = CRF(configs_ner_params.num_tags, sparse_target=True)\n",
    "\n",
    "        self.dense = layers.TimeDistributed(layers.Dense(units=self.hiden_units, \n",
    "                                                         activation='relu'))\n",
    "\n",
    "        self.classifier_softmax = layers.TimeDistributed(layers.Dense(units=configs_ner_params.num_tags, \n",
    "                                                                      activation='softmax'))\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        X = self.embedding(inputs)\n",
    "        X = self.dropout(X)\n",
    "        X = self.bilstm(X)\n",
    "        \n",
    "        if self.use_crf:\n",
    "            \n",
    "            X = self.dense_crf(X)\n",
    "            X = self.classifier_crf(X)\n",
    "        else:\n",
    "            \n",
    "            X = self.dense(X)\n",
    "            X = self.classifier_softmax(X)\n",
    "            \n",
    "        return X\n",
    "        \n",
    "    def model(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            Implementação baseada na API Funcional, permite utilizar o método 'model.summary' \n",
    "            antes de executar o método 'model.fit'\n",
    "            \n",
    "            Retorna o modelo compilado com base no classificador CRF / SOFTMAX\n",
    "            \n",
    "            parâmetro: use_crf\n",
    "        \"\"\"\n",
    "        \n",
    "        X = layers.Input(shape=(self.configs_ner_params.max_len,))\n",
    "\n",
    "        X = Model(inputs=[X], outputs=self.call(X))\n",
    "        \n",
    "        optm = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        if self.use_crf:\n",
    "            X.compile(optimizer=optm,\n",
    "                      loss=[self.classifier_crf.loss],\n",
    "                      metrics=[self.classifier_crf.accuracy])\n",
    "        else:\n",
    "            X.compile(optimizer=optm,\n",
    "                      loss=losses.CategoricalCrossentropy(),\n",
    "                      metrics=metrics.CategoricalAccuracy('accuracy'))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c15699-125f-41cd-84c6-3aef40c82f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1999996it [02:05, 15988.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrado 1999996 Word Vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93220/93220 [00:00<00:00, 298128.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidos: 23816 Tokens | Perdidos: 72067 Tokens\n",
      "CPU times: user 2min, sys: 5.64 s, total: 2min 6s\n",
      "Wall time: 2min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_path = './crawl-300d-2M.vec'\n",
    "\n",
    "glove_embeddings = \\\n",
    "build_matrix_embeddings(path=file_path,\n",
    "                        num_tokens=data_ner.num_words, \n",
    "                        embedding_dim=300, \n",
    "                        word_index=data_ner.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tribal-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NER_MODEL(data_ner, \n",
    "                  embeddings=glove_embeddings,\n",
    "                  use_crf=True).model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "korean-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 66)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 66, 300)           27966000  \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 66, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 66, 256)           439296    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 66, 10)            2570      \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    (None, 66, 10)            100       \n",
      "=================================================================\n",
      "Total params: 28,407,966\n",
      "Trainable params: 28,407,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "terminal-christmas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/mpgxc/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "441/441 [==============================] - 280s 612ms/step - loss: 17.5566 - viterbi_accuracy: 0.9132 - val_loss: 90.7243 - val_viterbi_accuracy: 0.9664\n",
      "Epoch 2/15\n",
      "441/441 [==============================] - 322s 730ms/step - loss: 5.6449 - viterbi_accuracy: 0.9725 - val_loss: 89.0150 - val_viterbi_accuracy: 0.9700\n",
      "Epoch 3/15\n",
      "441/441 [==============================] - 352s 798ms/step - loss: 3.5032 - viterbi_accuracy: 0.9812 - val_loss: 87.8437 - val_viterbi_accuracy: 0.9589\n",
      "Epoch 4/15\n",
      "441/441 [==============================] - 334s 757ms/step - loss: 2.3736 - viterbi_accuracy: 0.9866 - val_loss: 87.2452 - val_viterbi_accuracy: 0.9456\n",
      "Epoch 5/15\n",
      "441/441 [==============================] - 337s 763ms/step - loss: 1.6348 - viterbi_accuracy: 0.9903 - val_loss: 86.9426 - val_viterbi_accuracy: 0.9458\n",
      "Epoch 6/15\n",
      "441/441 [==============================] - 311s 705ms/step - loss: 1.1579 - viterbi_accuracy: 0.9931 - val_loss: 86.8031 - val_viterbi_accuracy: 0.9446\n",
      "Epoch 7/15\n",
      "441/441 [==============================] - 279s 632ms/step - loss: 0.8519 - viterbi_accuracy: 0.9949 - val_loss: 86.8383 - val_viterbi_accuracy: 0.9444\n",
      "Epoch 8/15\n",
      "441/441 [==============================] - 278s 631ms/step - loss: 0.6387 - viterbi_accuracy: 0.9962 - val_loss: 87.0195 - val_viterbi_accuracy: 0.9351\n",
      "Epoch 9/15\n",
      "441/441 [==============================] - 282s 640ms/step - loss: 0.4982 - viterbi_accuracy: 0.9970 - val_loss: 87.1188 - val_viterbi_accuracy: 0.9354\n",
      "Epoch 10/15\n",
      "441/441 [==============================] - 286s 649ms/step - loss: 0.4003 - viterbi_accuracy: 0.9976 - val_loss: 87.4588 - val_viterbi_accuracy: 0.9312\n",
      "Epoch 11/15\n",
      "441/441 [==============================] - 284s 643ms/step - loss: 0.3160 - viterbi_accuracy: 0.9982 - val_loss: 87.5492 - val_viterbi_accuracy: 0.3289\n",
      "Epoch 12/15\n",
      "441/441 [==============================] - 284s 645ms/step - loss: 0.2574 - viterbi_accuracy: 0.9985 - val_loss: 87.8919 - val_viterbi_accuracy: 0.2780\n",
      "Epoch 13/15\n",
      "441/441 [==============================] - 284s 644ms/step - loss: 0.2173 - viterbi_accuracy: 0.9987 - val_loss: 88.1712 - val_viterbi_accuracy: 0.2789\n",
      "Epoch 14/15\n",
      "441/441 [==============================] - 284s 645ms/step - loss: 0.1803 - viterbi_accuracy: 0.9989 - val_loss: 88.5319 - val_viterbi_accuracy: 0.2769\n",
      "Epoch 15/15\n",
      "441/441 [==============================] - 284s 644ms/step - loss: 0.1508 - viterbi_accuracy: 0.9992 - val_loss: 88.8848 - val_viterbi_accuracy: 0.2759\n",
      "CPU times: user 7h 48min 4s, sys: 1h 26min 34s, total: 9h 14min 39s\n",
      "Wall time: 1h 14min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "History = model.fit(X_TRAIN,\n",
    "                    Y_TRAIN,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=64, \n",
    "                    epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "premier-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 14s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_TEST, verbose=1, batch_size=64)\n",
    "                      \n",
    "y_pred, y_true = \\\n",
    "np.argmax(preds, axis=-1), \\\n",
    "np.argmax(Y_TEST, -1)\n",
    "\n",
    "pred_tag, true_tag = \\\n",
    "data_ner.parser2categorical(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a90fbd04-1c1d-40a0-a1c3-fe79aa2e86b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpgxc/anaconda3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       1.00      1.00      1.00     13425\n",
      "         LOC       0.58      0.67      0.62      6521\n",
      "        MISC       0.36      0.41      0.39      4523\n",
      "         ORG       0.46      0.46      0.46      3294\n",
      "         PER       0.61      0.64      0.63      5686\n",
      "\n",
      "   micro avg       0.70      0.74      0.72     33449\n",
      "   macro avg       0.60      0.64      0.62     33449\n",
      "weighted avg       0.71      0.74      0.73     33449\n",
      "\n",
      "=========================\n",
      "Precision: \t 0.7007953968522592\n",
      "Recall: \t 0.7428024754103262\n",
      "F1: \t\t 0.7211877567014499\n"
     ]
    }
   ],
   "source": [
    "all_metrics(pred_tag, true_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad1205-49e5-4e00-a384-9db2780eb636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
